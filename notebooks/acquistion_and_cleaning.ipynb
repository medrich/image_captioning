{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635fbc07-9337-4e2e-8fcf-ebd840cf8329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 18:16:28.261569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-18 18:16:28.261590: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/tmp/ipykernel_7732/2053491181.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88250835a97420fa8160a8384050e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import string\n",
    "from pickle import dump, load\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a14a68-4515-4bec-b0e5-7763dd9d5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ab46f8-3957-49ee-8a80-6d324a0deb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, and test sets as dataframes\n",
    "\n",
    "# training data\n",
    "with open('data/annotations/train.json') as json_train:\n",
    "    train_data = json.load(json_train)    \n",
    "train_imgs_df = pd.DataFrame(train_data['images'])\n",
    "train_captions_df = pd.DataFrame(train_data['annotations'])\n",
    "\n",
    "#validation data\n",
    "with open('data/annotations/val.json') as json_val:\n",
    "    val_data = json.load(json_val)\n",
    "val_imgs_df = pd.DataFrame(val_data['images'])\n",
    "val_captions_df = pd.DataFrame(val_data['annotations'])\n",
    "\n",
    "#test data\n",
    "with open('data/annotations/test.json') as json_test:\n",
    "    test_data = json.load(json_test)\n",
    "test_imgs_df = pd.DataFrame(test_data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135ef7b4-0591-49c9-9751-420b1136f8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23431 entries, 0 to 23430\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   file_name      23431 non-null  object\n",
      " 1   vizwiz_url     23431 non-null  object\n",
      " 2   id             23431 non-null  int64 \n",
      " 3   text_detected  23431 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 572.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_imgs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fa0592-4bd0-47ac-8c26-defd888de3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117155 entries, 0 to 117154\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   caption        117155 non-null  object\n",
      " 1   image_id       117155 non-null  int64 \n",
      " 2   is_precanned   117155 non-null  bool  \n",
      " 3   is_rejected    117155 non-null  bool  \n",
      " 4   id             117155 non-null  int64 \n",
      " 5   text_detected  117155 non-null  bool  \n",
      "dtypes: bool(3), int64(2), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_captions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20bffa0-72e2-4fcf-b5af-b14b4449f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7750 entries, 0 to 7749\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   file_name      7750 non-null   object\n",
      " 1   vizwiz_url     7750 non-null   object\n",
      " 2   id             7750 non-null   int64 \n",
      " 3   text_detected  7750 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 189.3+ KB\n"
     ]
    }
   ],
   "source": [
    "val_imgs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14abaa88-6283-42a0-9be2-a459bc1d5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38750 entries, 0 to 38749\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   caption        38750 non-null  object\n",
      " 1   image_id       38750 non-null  int64 \n",
      " 2   is_precanned   38750 non-null  bool  \n",
      " 3   is_rejected    38750 non-null  bool  \n",
      " 4   id             38750 non-null  int64 \n",
      " 5   text_detected  38750 non-null  bool  \n",
      "dtypes: bool(3), int64(2), object(1)\n",
      "memory usage: 1021.9+ KB\n"
     ]
    }
   ],
   "source": [
    "val_captions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89be4a78-1992-4704-8c0c-8cdb3d1c6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   file_name      8000 non-null   object\n",
      " 1   vizwiz_url     8000 non-null   object\n",
      " 2   id             8000 non-null   int64 \n",
      " 3   text_detected  8000 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test_imgs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d22d40-8a75-41f4-89b5-8636022320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_captions_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69b1363-f74e-4323-8355-c88718e5d8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs_df) + len(val_imgs_df) + len(test_imgs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853979ef-0c44-464e-9dc8-327302221821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155905"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_captions_df) + len(val_captions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a81489-c016-4f98-a70e-0784ee1b85f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>id</th>\n",
       "      <th>text_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VizWiz_train_00000000.jpg</td>\n",
       "      <td>https://ivc.ischool.utexas.edu/VizWiz_visualiz...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://ivc.ischool.utexas.edu/VizWiz_visualiz...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VizWiz_train_00000002.jpg</td>\n",
       "      <td>https://ivc.ischool.utexas.edu/VizWiz_visualiz...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VizWiz_train_00000003.jpg</td>\n",
       "      <td>https://ivc.ischool.utexas.edu/VizWiz_visualiz...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VizWiz_train_00000004.jpg</td>\n",
       "      <td>https://ivc.ischool.utexas.edu/VizWiz_visualiz...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  \\\n",
       "0  VizWiz_train_00000000.jpg   \n",
       "1  VizWiz_train_00000001.jpg   \n",
       "2  VizWiz_train_00000002.jpg   \n",
       "3  VizWiz_train_00000003.jpg   \n",
       "4  VizWiz_train_00000004.jpg   \n",
       "\n",
       "                                          vizwiz_url  id  text_detected  \n",
       "0  https://ivc.ischool.utexas.edu/VizWiz_visualiz...   0           True  \n",
       "1  https://ivc.ischool.utexas.edu/VizWiz_visualiz...   1           True  \n",
       "2  https://ivc.ischool.utexas.edu/VizWiz_visualiz...   2           True  \n",
       "3  https://ivc.ischool.utexas.edu/VizWiz_visualiz...   3           True  \n",
       "4  https://ivc.ischool.utexas.edu/VizWiz_visualiz...   4           True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2b6ccd-cc18-4e76-b8ee-77516446498f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>image_id</th>\n",
       "      <th>is_precanned</th>\n",
       "      <th>is_rejected</th>\n",
       "      <th>id</th>\n",
       "      <th>text_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITS IS A BASIL LEAVES CONTAINER ITS CONTAINS T...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A green and white plastic condiment bottle con...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A bottle of spices in a plastic container layi...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>some basil leaves in a container on a counter</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  image_id  is_precanned  \\\n",
       "0  ITS IS A BASIL LEAVES CONTAINER ITS CONTAINS T...         0         False   \n",
       "1  A green and white plastic condiment bottle con...         0         False   \n",
       "2  Quality issues are too severe to recognize vis...         0          True   \n",
       "3  A bottle of spices in a plastic container layi...         0         False   \n",
       "4      some basil leaves in a container on a counter         0         False   \n",
       "\n",
       "   is_rejected  id  text_detected  \n",
       "0        False   0           True  \n",
       "1        False   1           True  \n",
       "2         True   2           True  \n",
       "3        False   3           True  \n",
       "4        False   4           True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc450f4b-a19c-40bd-938b-e0ed83969183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to create a dictionary where the keys are the image files and the captions are the values\n",
    "\n",
    "def image_caption_connector(images,captions):\n",
    "    \n",
    "    descriptions = {}\n",
    "    cap_idx = 0\n",
    "    \n",
    "    for img in range(len(images)):\n",
    "        caps = []\n",
    "        \n",
    "        for cap in captions['caption'][cap_idx:cap_idx+5]:\n",
    "            caps.append(cap)\n",
    "            \n",
    "            if len(caps) > 4:\n",
    "                cap_idx += 5\n",
    "                break\n",
    "            \n",
    "        current_img = images['file_name'][img]\n",
    "        descriptions[current_img] = caps\n",
    "            \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f0507b-46b9-4a04-a85e-661bf2f3208f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_caption_connector(train_imgs_df[:5], train_captions_df[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb221ebe-db26-45c7-9430-174f78d1cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cap_dict = image_caption_connector(train_imgs_df, train_captions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3f97701-2689-46cc-bdc8-3bee7866d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cap_dict = image_caption_connector(val_imgs_df, val_captions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f237a90-cee7-46a1-956e-37bd23cafc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_cap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36cf04c0-cef8-4e35-a55c-233a775b118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_check = list(img_cap_dict)[19763]\n",
    "val_check = list(img_cap_dict.values())[19763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac30430c-63db-4092-b4b8-e5e0756e91c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VizWiz_train_00019763.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b4727a-1642-45b9-8e7e-a51a981791ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quality issues are too severe to recognize visual content.',\n",
       " 'Wrist of a person wearing a silver watch holding something',\n",
       " 'A human hand and arm, wearing a watch and  holding something blue just out of frame.',\n",
       " \"A photo of someone's left hand wearing a silver watch holding an object.\",\n",
       " 'a hand wearing a metal watch carrying a hard to identify object']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee88286-640e-4b8b-803d-0aff92c6d463",
   "metadata": {},
   "source": [
    "# A Note\n",
    "\n",
    "Not entirely sure why, but the local images folder on my pc has 23953 images in it, but the .json file appears to only be bringing the first 23430 into a dataframe. This represents ~2% of overall training data that I have no annotations for and thus can't use. Probably not a big deal but I should still note this, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b9c470-8bd4-4fca-8c6b-1997226ad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to clean the text in a few basic ways\n",
    "\n",
    "def text_cleaner(img_caps):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    \n",
    "    for img,cap in img_caps.items():\n",
    "        \n",
    "        for i,caption in enumerate(cap):\n",
    "            caption.replace(\"-\",\" \")\n",
    "            desc = caption.split()\n",
    "            \n",
    "            #lowercase\n",
    "            desc = [w.lower() for w in desc]\n",
    "            \n",
    "            #remove punctuation\n",
    "            desc = [w.translate(table) for w in desc]\n",
    "            \n",
    "            #remove digits\n",
    "            desc = [w for w in desc if(w.isalpha())]\n",
    "            \n",
    "            #convert back to string\n",
    "            caption = ' '.join(desc)\n",
    "            img_caps[img][i] = caption\n",
    "    \n",
    "    return img_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58cbf97b-d0b2-4efb-a2b2-8c4d3f5ec15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_caps = text_cleaner(img_cap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7e3b67-2bdf-45e5-8057-755feccf48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cleaned_cap = text_cleaner(val_cap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715c086c-ed4a-437c-9ee6-9389402c738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_check = list(img_cap_dict)[19763]\n",
    "val_check = list(img_cap_dict.values())[19763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c59f06d-9d9a-41ad-9f81-e13e4e4cd0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VizWiz_train_00019763.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e81f4f20-88af-4164-af07-ba93febf64de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quality issues are too severe to recognize visual content',\n",
       " 'wrist of a person wearing a silver watch holding something',\n",
       " 'a human hand and arm wearing a watch and holding something blue just out of frame',\n",
       " 'a photo of someones left hand wearing a silver watch holding an object',\n",
       " 'a hand wearing a metal watch carrying a hard to identify object']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46a4180e-a71f-41d5-8f01-73ed0228c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocabulary of all the unique words\n",
    "\n",
    "def vocabber(corpus):\n",
    "    vocab = set()\n",
    "    \n",
    "    for k in corpus.keys():\n",
    "        [vocab.update(c.split()) for c in corpus[k]]\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64d66f7b-f88d-411e-bf6a-b57f605d3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vocabber(img_cap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee919a77-79ab-4a00-8b8b-0b5252e4d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vocab = vocabber(val_cap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "754540ac-f451-4e5f-ab42-c1672b838e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "372d5cf4-edef-4e49-a075-d66a116f72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconstruct the dictonary and organize it into one text file\n",
    "\n",
    "def save_progress(captions, filename):\n",
    "    lines = []\n",
    "    \n",
    "    for k, caps in captions.items():\n",
    "        for cap in caps:\n",
    "            lines.append(k + '\\t' + cap)\n",
    "    \n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "984b883c-2968-427a-9cc4-bcf903dd3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_progress(cleaned_caps, 'images_with_associated_captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e40617b1-b75b-40bd-96dd-183c11fe26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_progress(val_cleaned_cap, 'val_imgs_w_caps.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d87c1d78-cd9f-4e0f-8efd-2fcb85b47ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = []\n",
    "\n",
    "for img in train_imgs_df['file_name']:\n",
    "    img_names.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce446134-0bf3-49bc-af93-7e0f66beb100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23431"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f5c2a68-b1da-4344-a7c1-dd700d9bc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img_names.txt\", \"w\") as imgs:\n",
    "    imgs.write(str(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d328270c-e73f-4089-a02d-9713f7bf9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_names = []\n",
    "\n",
    "for img in val_imgs_df['file_name']:\n",
    "    val_img_names.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a9c4700-c1a0-47c6-a777-02a45f71733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"val_img_names.txt\", \"w\") as imgs:\n",
    "    imgs.write(str(val_img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "802e4021-afe9-47cf-8530-aeb3885094dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from VALIDATION mages using Xception transfer learning\n",
    "\n",
    "def get_val_img_features(filepath):\n",
    "\n",
    "    xfer_model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "\n",
    "    for img in tqdm(os.listdir(filepath)):\n",
    "        #print(type(img))  \n",
    "        #img_name = subfolder + '/' + img\n",
    "        #print(img)\n",
    "        img_name = 'data/vizwiz data/val' + '/' + img\n",
    "        image = Image.open(img_name.li.)\n",
    "        image = image.resize((299,299))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image/127.5\n",
    "        image -= 1.0\n",
    "\n",
    "        feature = xfer_model.predict(image)\n",
    "        features[img] = feature\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d3c4087-da5d-481e-bc5b-964987a3ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_path = 'data/vizwiz data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f4aa01f-2cb6-4e1f-ba53-ec9bc4809817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14777/1444478676.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img in tqdm(os.listdir(filepath)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad9f36394a547899f56e5176bc4fb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_features = get_val_img_features(val_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45daf333-c24c-4c80-a191-9fd81bc3d552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7750"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ad376d1-e5ef-4a89-9c2f-87f94d58e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(val_features, open('val_features.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e205fc58-1a63-4ac5-ba7b-ac1b87f45ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_check = list(val_features)[0]\n",
    "val_check = list(val_features.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a337744-cc00-4194-b9c1-850feac94f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VizWiz_val_00000453.jpg'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccd252ab-10c3-4f7e-b796-c07cbbc5c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10363426, 0.14685044, 0.00564226, ..., 0.        , 0.16573177,\n",
       "        0.16373302]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bca76-dfd3-4aa1-99ed-fe11e868ed35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
