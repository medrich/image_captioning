{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "executionInfo": {
     "elapsed": 2812,
     "status": "ok",
     "timestamp": 1650241567825,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "iWWnztxzjb57",
    "outputId": "4ead6948-1609-4148-8af4-2a660d8a5079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be014f60c664d508ec6f9f1dfdb7a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650241567826,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "RoqnhEpFlDJw"
   },
   "outputs": [],
   "source": [
    "# extract features from images using Xception transfer learning\n",
    "\n",
    "def get_img_features(filepath):\n",
    "\n",
    "    xfer_model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "\n",
    "    for dir in tqdm(os.listdir(filepath)):\n",
    "        subfolder = str(filepath + '/' + dir)\n",
    "        for img in tqdm(os.listdir(subfolder)):\n",
    "        print(type(img))  \n",
    "        img_name = subfolder + '/' + img\n",
    "        #print(img_name)\n",
    "        image = Image.open(img_name)\n",
    "        image = image.resize((299,299))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image/127.5\n",
    "        image -= 1.0\n",
    "\n",
    "        feature = xfer_model.predict(image)\n",
    "        features[img] = feature\n",
    "    \n",
    "    return features\n",
    "\n",
    "# transfer learning techniques adapted from neptune.ai's Derrick Mwiti (https://neptune.ai/blog/transfer-learning-guide-examples-for-images-and-text-in-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1650241568494,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "HgqkfF9-nYR-"
   },
   "outputs": [],
   "source": [
    "#img_dirs = []\n",
    "\n",
    "#root = '/content/drive/MyDrive/vizwiz/train'\n",
    "\n",
    "#for i in range(1,17):\n",
    "#  img_dirs.append(root + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1650241568684,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "IFOCB324neVv"
   },
   "outputs": [],
   "source": [
    "#img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650241569122,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "D3NNbkGTqfEi"
   },
   "outputs": [],
   "source": [
    "# notebook originally written on Colab\n",
    "\n",
    "root_path = '/content/drive/MyDrive/vizwiz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1650241572308,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "BEbB6ZcQrmKE"
   },
   "outputs": [],
   "source": [
    "#data_paths = [os.path.join(root_path, f) for f in os.listdir(root_path)]\n",
    "#data_paths = [i for i in data_paths if os.path.isfile(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650217496597,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "09EwrRvTnnl9"
   },
   "outputs": [],
   "source": [
    "#features = get_img_features(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650217497239,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "iilt125_p_nd"
   },
   "outputs": [],
   "source": [
    "#len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650217497791,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "9rxeIrx3t8F3"
   },
   "outputs": [],
   "source": [
    "#dump(features, open('features.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650217498077,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "dbB9rLhC5Dtz"
   },
   "outputs": [],
   "source": [
    "#features = load(open('/content/drive/MyDrive/features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1650241573613,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "UGhPZpJUAgkv"
   },
   "outputs": [],
   "source": [
    "# load img_names.txt\n",
    "\n",
    "def get_image_names(filepath):\n",
    "    file = load_doc(filepath)\n",
    "    imgs = file.split(',')[:-1]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for f in imgs:\n",
    "        path = ''\n",
    "        path = f[2:len(f)-1]\n",
    "        output.append(path)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650241577346,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "zhnThqQ1D4qK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650241577346,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "Xz9AAG_dDkKS"
   },
   "outputs": [],
   "source": [
    "#load the clean descriptions\n",
    "\n",
    "def get_clean_descriptions(filepath, images):\n",
    "    #load the cleaned up descriptions\n",
    "    file = load_doc(filepath)\n",
    "    descriptions = {}\n",
    "\n",
    "    for line in file.split('\\n'):\n",
    "    \n",
    "        words = line.split()\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "    \n",
    "        image, caption = words[0], words[1:]\n",
    "\n",
    "        if image in images:\n",
    "            if image not in descriptions:\n",
    "            descriptions[image] = []\n",
    "\n",
    "            desc = '<start> ' + \" \".join(caption) + ' <end>'\n",
    "            descriptions[image].append(desc)\n",
    "\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1650241580093,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "Xjh5kASYEvYK"
   },
   "outputs": [],
   "source": [
    "#load the features\n",
    "\n",
    "def load_features(imgs):\n",
    "    #load all the features!\n",
    "    all_features = load(open('/content/drive/MyDrive/features.p', 'rb'))\n",
    "\n",
    "    #then get only the needed features\n",
    "    features = {k:all_features[k] for k in imgs}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1650241580331,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "1BQs-IOsFL1a"
   },
   "outputs": [],
   "source": [
    "img_names_text = '/content/drive/MyDrive/img_names.txt'\n",
    "\n",
    "# function to load text file into memory\n",
    "\n",
    "def load_doc(filepath):\n",
    "    #open a file as read only\n",
    "    file = open(filepath, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1650242382447,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "8NJWFHTlUt2E"
   },
   "outputs": [],
   "source": [
    "train_imgs = get_image_names(img_names_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 26752,
     "status": "ok",
     "timestamp": 1650242409731,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "RaaPr8_6U3DC"
   },
   "outputs": [],
   "source": [
    "train_descriptions = get_clean_descriptions('/content/drive/MyDrive/images_with_associated_captions.txt', train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 4192,
     "status": "ok",
     "timestamp": 1650242413912,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "7Hp-BJh7Vvzs"
   },
   "outputs": [],
   "source": [
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1650241588147,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "RDMGpIuUhwfR"
   },
   "outputs": [],
   "source": [
    "val_img_path = '/content/drive/MyDrive/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1650241589132,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "oeEhpLTMh6j8"
   },
   "outputs": [],
   "source": [
    "val_imgs = get_image_names('/content/drive/MyDrive/val_img_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3398,
     "status": "ok",
     "timestamp": 1650241603907,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "i9MzjMXcV_99"
   },
   "outputs": [],
   "source": [
    "val_descriptions = get_clean_descriptions('/content/drive/MyDrive/val_imgs_w_caps.txt', val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650241603908,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "enK7DrGrlVKK"
   },
   "outputs": [],
   "source": [
    "# extract features from VALIDATION mages using Xception transfer learning\n",
    "\n",
    "def get_val_img_features(filepath):\n",
    "\n",
    "    xfer_model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "\n",
    "    for img in tqdm(os.listdir(filepath)):\n",
    "        print(type(img))  \n",
    "        #img_name = subfolder + '/' + img\n",
    "        print(img_name)\n",
    "        #image = Image.open(img)\n",
    "        #image = image.resize((299,299))\n",
    "        #image = np.expand_dims(image, axis=0)\n",
    "        #image = image/127.5\n",
    "        #image -= 1.0\n",
    "\n",
    "        #feature = xfer_model.predict(image)\n",
    "        #features[img] = feature\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1650241606507,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "Gi7QYHGGk7Pd"
   },
   "outputs": [],
   "source": [
    "val_features = load(open('/content/drive/MyDrive/val_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1650241609460,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "FXnyyQL5WKFG",
    "outputId": "5f500167-68f5-4d5f-833a-afa6e67906d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7750"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1650241673410,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "3sTqRtAAEVMh",
    "outputId": "147121c5-ace5-40c2-e1a9-7019e6e7be66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1650242034044,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "4XfGIsTOE4Kk"
   },
   "outputs": [],
   "source": [
    "X_val = [k for k in val_features.keys()]\n",
    "y_val = [f for f in val_features.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1650242021776,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "DXceCayGFV-Q",
    "outputId": "bf808300-5f95-4af5-8486-8612d6e4ad3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10363426, 0.14685044, 0.00564226, ..., 0.        , 0.16573177,\n",
       "        0.16373302]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_val[0]\n",
    "y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1650242042442,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "nl9u_AK_WOdu"
   },
   "outputs": [],
   "source": [
    "# convert dict to clean list of captions\n",
    "\n",
    "def d_to_l(desc):\n",
    "    corpus = []\n",
    "\n",
    "    for k in desc.keys():\n",
    "        [corpus.append(text) for text in desc[k]]\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1650242258748,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "G43H7H8CGLFm"
   },
   "outputs": [],
   "source": [
    "#validation_test = d_to_l(val_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650242259008,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "IiCWsCzGGWhv"
   },
   "outputs": [],
   "source": [
    "#validation_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1650242044776,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "0QeF5JoNZ07j"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(desc):\n",
    "    corpus = d_to_l(desc)\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    return tokenizer, max(len(text.split()) for text in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1650242428960,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "EK-g2m0aaR-E"
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "\n",
    "tokens = tokenizer[0]\n",
    "longest_caption = tokenizer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650242429422,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "zEB7Lp2-aeZA"
   },
   "outputs": [],
   "source": [
    "#dump(tokens, open('tokens.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1650242430079,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "jxdvPDi0amAm"
   },
   "outputs": [],
   "source": [
    "lex_count = len(tokens.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1650242431135,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "tofM9ae4brw8",
    "outputId": "a96d5a6d-a078-4065-e2d3-9a1906d03294"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18031"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650242431594,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "nYkriobEarc5",
    "outputId": "ea359206-ad49-46f3-bff0-d5c74ca4bdac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1650242433818,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "LAJ6peiJbngL"
   },
   "outputs": [],
   "source": [
    "# since there are ~23000 images to train on, all with large feature vectors, I'll need a data generator to process batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650242434174,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "mHW5exGUccy5"
   },
   "outputs": [],
   "source": [
    "# create i/o sequence pairs from the iamge description\n",
    "\n",
    "def data_generator(captions, features, tokenizer, longest):\n",
    "    while 1:\n",
    "        for k, cap_list in captions.items():\n",
    "            #retrieve photo features\n",
    "            feature = features[k][0]\n",
    "            img_in, seq, word_out = make_seq(tokenizer, longest, cap_list, feature)\n",
    "\n",
    "            yield [[img_in, seq], word_out]\n",
    "            \n",
    "# data generator code inspired and guided by Abhishek Sharma (https://medium.com/mlearning-ai/image-captioning-using-deep-learning-with-source-code-easy-explanation-3f2021a63f14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1650242434464,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "vOf9QLWKdjYt"
   },
   "outputs": [],
   "source": [
    "def make_seq(tokenizer, longest, cap_list, feature):\n",
    "      X1, X2, y = [], [], []\n",
    "\n",
    "      #iterate through each caption for a given image\n",
    "      for cap in cap_list:\n",
    "          #encode the sequence\n",
    "          seq = tokenizer.texts_to_sequences([cap])[0]\n",
    "\n",
    "          #split one sequence into multiple X,y pairs\n",
    "          for i in range(1, len(seq)):\n",
    "                #split into i/o pair\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                #pad input\n",
    "                in_seq = pad_sequences([in_seq], maxlen=longest)[0]\n",
    "                #encode output\n",
    "                out_seq = to_categorical([out_seq], num_classes=lex_count)[0]\n",
    "\n",
    "                #store\n",
    "                X1.append(feature)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "\n",
    "    return np.array(X1), np.array(X2), np.array(y) \n",
    "\n",
    "# code to make sequences specifically for image captioning purposes inspired and guided by Abhishek Sharma (https://medium.com/mlearning-ai/image-captioning-using-deep-learning-with-source-code-easy-explanation-3f2021a63f14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1650242436260,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "9YnUO9KKfVqk"
   },
   "outputs": [],
   "source": [
    "[a,b],c = next(data_generator(train_descriptions, train_features, tokens, longest_caption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650242436260,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "CwTAB_QXf2Pa",
    "outputId": "e9358b03-abbc-4816-b0fb-3475540a751c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2048)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650242436617,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "lyTMUKZggi3B",
    "outputId": "8643a0cb-b7c8-4381-cb2f-f5d5cb0fbb3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 112)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1650242437540,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "M4GZYcqGgn5w",
    "outputId": "dea948b4-1868-4e7f-a479-4e3488c08e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 18031)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650242438878,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "6U4jfQYqg1-n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1650242439668,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "pw4O2z-Iglx6"
   },
   "outputs": [],
   "source": [
    "# captioning model\n",
    "\n",
    "def setup(lex_count, longest_caption):\n",
    "  \n",
    "    #compress number of features from cnn\n",
    "    cnn_feats = Input(shape=(2048,))\n",
    "    features_1 = Dropout(0.5)(cnn_feats)\n",
    "    features_2 = Dense(256, activation='relu')(features_1)\n",
    "\n",
    "    #lstm sequence model\n",
    "    lstm_in = Input(shape=(longest_caption,))\n",
    "    sequences_1 = Embedding(lex_count, 256, mask_zero=True)(lstm_in)\n",
    "    sequences_2 = Dropout(0.5)(se1)\n",
    "    seequences_3 = LSTM(256)(sequecnes_2)\n",
    "\n",
    "    #merge the models\n",
    "    decoder_1 = add([features_2, sequences_3])\n",
    "    decoder_2 = Dense(256, activation='relu')(decoder_1)\n",
    "    outputs = Dense(lex_count, activation='softmax')(decoder_2)\n",
    "\n",
    "    #model it all\n",
    "    model = Model(inputs=[cnn_feats, lstm_in], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[])\n",
    "\n",
    "    #summarize\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5396,
     "status": "ok",
     "timestamp": 1650242448319,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "yBm_ZBAjjHRM",
    "outputId": "15423628-fad0-4899-fd3a-71987ad7378b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 23430 images in it.\n",
      "There are 23430 associatedcaptions; 5 for each image.\n",
      "23430 features were extracted.\n",
      "There are 18031 unique words.\n",
      "The longest caption is 112 characters long.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 112)]        0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 2048)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 112, 256)     4615936     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 112, 256)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          524544      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          525312      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 18031)        4633967     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,365,551\n",
      "Trainable params: 10,365,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TRAIN IT, FINALLY\n",
    "\n",
    "print(f'The training dataset has {len(train_imgs)} images in it.')\n",
    "print(f'There are {len(train_descriptions)} associatedcaptions; 5 for each image.')\n",
    "print(f'{len(train_features)} features were extracted.')\n",
    "print(f'There are {lex_count} unique words.')\n",
    "print(f'The longest caption is {longest_caption} characters long.')\n",
    "\n",
    "model = setup(lex_count, longest_caption)\n",
    "epochs = 30\n",
    "steps = (len(train_descriptions))*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kvoa4Z0UkInl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - ETA: 0s - loss: 4.4024"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-bdaeb6c6de3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_descriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongest_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 987\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'str'>\"}), (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"})"
     ]
    }
   ],
   "source": [
    "os.mkdir('models')\n",
    "for i in range(epochs,epochs+1):\n",
    "    generator = data_generator(train_descriptions, train_features, tokens, longest_caption)\n",
    "    model.fit(generator, epochs=1, validation_data=(X_val, y_val), steps_per_epoch=steps, verbose=1)\n",
    "    model.save('models/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6O5gIsQlR5y"
   },
   "outputs": [],
   "source": [
    "def get_img_features_vgg16(filepath):\n",
    "\n",
    "  xfer_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "  features = {}\n",
    "\n",
    "  for dir in tqdm(os.listdir(filepath)):\n",
    "    subfolder = str(filepath + '/' + dir)\n",
    "    for img in tqdm(os.listdir(subfolder)):\n",
    "      #print(type(img))  \n",
    "      img_name = subfolder + '/' + img\n",
    "      #print(img_name)\n",
    "      image = Image.open(img_name)\n",
    "      image = image.resize((299,299))\n",
    "      image = np.expand_dims(image, axis=0)\n",
    "      image = image/127.5\n",
    "      image -= 1.0\n",
    "\n",
    "      feature = xfer_model.predict(image)\n",
    "      features[img] = feature\n",
    "    \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SyQJIlhhRNZ"
   },
   "outputs": [],
   "source": [
    "#vgg_features = get_img_features_vgg16(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhreQPTRu1od"
   },
   "outputs": [],
   "source": [
    "#dump(vgg_features, open('vgg_features.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tt95qmvYf9of"
   },
   "outputs": [],
   "source": [
    "#vgg_features = load(open('/content/drive/MyDrive/vgg_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl3VoZOxu2ak"
   },
   "outputs": [],
   "source": [
    "def load_vgg_features(imgs):\n",
    "  #load all the features!\n",
    "  all_features = load(open('/content/drive/MyDrive/vgg_features.p', 'rb'))\n",
    "\n",
    "  features = {k:all_features[k] for k in imgs}\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0QB9P1FCX8_"
   },
   "outputs": [],
   "source": [
    "vgg_imgs = get_image_names(img_names_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ael2LACec4"
   },
   "outputs": [],
   "source": [
    "vgg_descriptions = get_clean_descriptions('/content/drive/MyDrive/images_with_associated_captions.txt', vgg_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eEAuAP7CkR8"
   },
   "outputs": [],
   "source": [
    "vgg_features = load_vgg_features(vgg_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zdnSxJyCszC"
   },
   "outputs": [],
   "source": [
    "vgg_tokenizer = create_tokenizer(vgg_descriptions)\n",
    "\n",
    "vgg_tokens = vgg_tokenizer[0]\n",
    "vgg_longest_caption = vgg_tokenizer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE14UdfKh151"
   },
   "outputs": [],
   "source": [
    "vgg_lex_count = len(vgg_tokens.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEu_Zk97iqxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rETaTrbHEJNi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAPO0paWmxZE"
   },
   "outputs": [],
   "source": [
    "# captioning model with VGG\n",
    "\n",
    "def setup_for_vgg(vgg_lex_count, vgg_longest_caption):\n",
    "  \n",
    "  #compress number of features from cnn\n",
    "  cnn_feats = Input(shape=(2048,))\n",
    "  fe1 = Dropout(0.5)(cnn_feats)\n",
    "  fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "  #lstm sequence model\n",
    "  lstm_in = Input(shape=(vgg_longest_caption,))\n",
    "  se1 = Embedding(vgg_lex_count, 256, mask_zero=True)(lstm_in)\n",
    "  se2 = Dropout(0.5)(se1)\n",
    "  se3 = LSTM(256)(se2)\n",
    "\n",
    "  #merge the models\n",
    "  dec1 = add([fe2, se3])\n",
    "  dec2 = Dense(256, activation='relu')(dec1)\n",
    "  outputs = Dense(vgg_lex_count, activation='softmax')(dec2)\n",
    "\n",
    "  #model it all\n",
    "  model = Model(inputs=[cnn_feats, lstm_in], outputs=outputs)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "  #summarize\n",
    "  print(model.summary())\n",
    "  plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4639,
     "status": "ok",
     "timestamp": 1650167242174,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "rmSOdAl9nZ4T",
    "outputId": "b334423b-f135-4dd1-bd59-c0a39695b084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 23430 images in it.\n",
      "There are 23430 associatedcaptions; 5 for each image.\n",
      "23430 features were extracted.\n",
      "There are 18031 unique words.\n",
      "The longest caption is 112 characters long.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 112)]        0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 2048)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 112, 256)     4615936     ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 2048)         0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 112, 256)     0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 256)          524544      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 256)          525312      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 256)          0           ['dense_12[0][0]',               \n",
      "                                                                  'lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 256)          65792       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 18031)        4633967     ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,365,551\n",
      "Trainable params: 10,365,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TRAIN IT, FINALLY\n",
    "\n",
    "print(f'The training dataset has {len(vgg_imgs)} images in it.')\n",
    "print(f'There are {len(vgg_descriptions)} associatedcaptions; 5 for each image.')\n",
    "print(f'{len(vgg_features)} features were extracted.')\n",
    "print(f'There are {vgg_lex_count} unique words.')\n",
    "print(f'The longest caption is {vgg_longest_caption} characters long.')\n",
    "\n",
    "model = setup_for_vgg(vgg_lex_count, vgg_longest_caption)\n",
    "epochs = 10\n",
    "steps = (len(vgg_descriptions))*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43371,
     "status": "error",
     "timestamp": 1650167300561,
     "user": {
      "displayName": "Matt Edrich",
      "userId": "05115134804914636834"
     },
     "user_tz": 360
    },
    "id": "AAwf9xp3ERje",
    "outputId": "77d4f0e0-4ae1-4699-94e4-551e86a0158f"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2a43d4d9fcf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_descriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_longest_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/vgg_model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/dense_12/MatMul' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-72-2a43d4d9fcf7>\", line 4, in <module>\n      model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/core/dense.py\", line 219, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_4/dense_12/MatMul'\nMatrix size-incompatible: In[0]: [57,512], In[1]: [2048,256]\n\t [[{{node model_4/dense_12/MatMul}}]] [Op:__inference_train_function_36870]"
     ]
    }
   ],
   "source": [
    "os.mkdir('models')\n",
    "for i in range(0,epochs):\n",
    "  generator = data_generator(vgg_descriptions, vgg_features, vgg_tokens, vgg_longest_caption)\n",
    "  model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "  model.save('models/vgg_model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk7Pq7faGxun"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W89Rpt6UG083"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNtTzHuM9Pl/nQaUzgwXQfQ",
   "collapsed_sections": [],
   "mount_file_id": "1gPG9zkNNTDDd4s5wQCTn0XXjO6MCGOX1",
   "name": "feature_extraction.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c78737fbeae43bf967494fc1a5a9c60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f641f44c74d43e2b884f7e3f7b9cfb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1149e2dbfb244a49b6e380855bd4d60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff581ddcaa8a4c33aa1bb1f96be75749",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_daf49adf957c4b98b8fae3589217e3f9",
      "value": 0
     }
    },
    "2a96fef01116480f97c1fc66a246898f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f2e975eb0ce447ca44a24f7560f34ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b0ee477114b4e5786294b0364609254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a96fef01116480f97c1fc66a246898f",
      "placeholder": "",
      "style": "IPY_MODEL_4f2e975eb0ce447ca44a24f7560f34ef",
      "value": ""
     }
    },
    "6ab110d560924d5cb3eb9a9f7ecae594": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be014f60c664d508ec6f9f1dfdb7a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b0ee477114b4e5786294b0364609254",
       "IPY_MODEL_1149e2dbfb244a49b6e380855bd4d60b",
       "IPY_MODEL_e49976b282da4a558c98448b1f441fc6"
      ],
      "layout": "IPY_MODEL_0f641f44c74d43e2b884f7e3f7b9cfb1"
     }
    },
    "daf49adf957c4b98b8fae3589217e3f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e49976b282da4a558c98448b1f441fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab110d560924d5cb3eb9a9f7ecae594",
      "placeholder": "",
      "style": "IPY_MODEL_0c78737fbeae43bf967494fc1a5a9c60",
      "value": " 0/? [00:09&lt;?, ?it/s]"
     }
    },
    "ff581ddcaa8a4c33aa1bb1f96be75749": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
